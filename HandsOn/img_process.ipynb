{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597811405399",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"opencvLogo.png\")\n",
    "cv2.namedWindow(\"Image\",cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Image\",img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imwrite(\"output.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       ...,\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]],\n\n       [[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255]]], dtype=uint8)"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "img = cv2.imread(\"opencvLogo.png\",1)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "521"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1600"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "len(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(img[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(521, 1600, 3)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "dtype('uint8')"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "256"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "2**8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([255, 255, 255], dtype=uint8)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "img[10, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[255, 255, 255, ..., 255, 255, 255],\n       [255, 255, 255, ..., 255, 255, 255],\n       [255, 255, 255, ..., 255, 255, 255],\n       ...,\n       [255, 255, 255, ..., 255, 255, 255],\n       [255, 255, 255, ..., 255, 255, 255],\n       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "img[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "2500800"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black Screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0]\n"
    }
   ],
   "source": [
    "black = np.zeros([150,200,1],'uint8')\n",
    "cv2.imshow('Black',black)\n",
    "print(black[0,0,:])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1 1 1]\n"
    }
   ],
   "source": [
    "ones = np.ones([150,200,3],'uint8')\n",
    "cv2.imshow('Ones',ones)\n",
    "print(ones[0,0,:])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White Screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[65535 65535 65535]\n"
    }
   ],
   "source": [
    "white = np.ones([150,200,3],'uint16')\n",
    "white *= (2**16-1)\n",
    "cv2.imshow(\"White\", white)\n",
    "print(white[0,0,:])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blue Screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[255   0   0]\n"
    }
   ],
   "source": [
    "color = ones.copy()\n",
    "color[:,:] = (255,0,0)\n",
    "cv2.imshow(\"Blue\", color)\n",
    "print(color[0,0,:])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Butterfly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(356, 493, 3)\n"
    }
   ],
   "source": [
    "color = cv2.imread('butterfly.jpg',1)\n",
    "cv2.imshow(\"Image\",color)\n",
    "cv2.moveWindow(\"Image\",0,0)\n",
    "print(color.shape)\n",
    "height, width, channels = color.shape\n",
    "\n",
    "b,g,r = cv2.split(color)\n",
    "\n",
    "rgb_split = np.empty([height,width*3,3],'uint8')\n",
    "\n",
    "rgb_split[:, 0:width] = cv2.merge([b,b,b])\n",
    "rgb_split[:, width:width*2] = cv2.merge([g,g,g])\n",
    "rgb_split[:, width*2:width*3] = cv2.merge([r,r,r])\n",
    "\n",
    "cv2.imshow(\"Channels\",rgb_split)\n",
    "cv2.moveWindow(\"Channels\",0,height)\n",
    "\n",
    "hsv = cv2.cvtColor(color, cv2.COLOR_BGR2HSV)\n",
    "h,s,v = cv2.split(hsv)\n",
    "hsv_split = np.concatenate((h,s,v), axis=1)\n",
    "cv2.imshow(\"Split HSV\", hsv_split)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel manuplation and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "color = cv2.imread('butterfly.jpg',1)\n",
    "\n",
    "gray = cv2.cvtColor(color, cv2.COLOR_RGB2GRAY)\n",
    "cv2.imwrite(\"gray.jpg\", gray)\n",
    "\n",
    "b = color[:,:,0]\n",
    "g = color[:,:,1]\n",
    "r = color[:,:,2]\n",
    "\n",
    "rgba = cv2.merge((b,g,r,g))\n",
    "cv2.imwrite(\"rgba.png\", rgba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blur, dilation and erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"thresh.jpg\")\n",
    "cv2.imshow(\"Original\", image)\n",
    "\n",
    "blur = cv2.GaussianBlur(image, (5,55),0)\n",
    "cv2.imshow(\"Blur\", blur)\n",
    "\n",
    "kernel = np.ones((5,5),'uint8')\n",
    "\n",
    "dilate = cv2.dilate(image,kernel,iterations=1)\n",
    "erode = cv2.erode(image,kernel,iterations=1)\n",
    "\n",
    "cv2.imshow(\"Dilate\", dilate)\n",
    "cv2.imshow(\"Erode\", erode)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale and Rotate Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"players.jpg\")\n",
    "\n",
    "#Scale\n",
    "img_half = cv2.resize(img, (0,0), fx=0.5, fy=0.5)\n",
    "img_streach = cv2.resize(img, (600,600))\n",
    "img_streach_near = cv2.resize(img, (600,600), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "cv2.imshow(\"Half\", img_half)\n",
    "cv2.imshow(\"Streach\", img_streach)\n",
    "cv2.imshow(\"Streach Near\", img_streach_near)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation\n",
    "M = cv2.getRotationMatrix2D((0,0), -30, 1)\n",
    "rotated = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "cv2.imshow(\"Rotated\", rotated)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use video input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    ch = cv2.waitKey(1)\n",
    "    if ch & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create custom interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Pressed 226 164\nPressed 377 270\nPressed 377 330\nPressed 363 375\nPressed 262 356\n"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "color = (0,255,0)\n",
    "line_width = 3\n",
    "radius = 100\n",
    "point = (0,0)\n",
    "\n",
    "def click(event, x, y, flags, param):\n",
    "    global point, pressed\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(\"Pressed\", x, y)\n",
    "        point = (x, y)\n",
    "\n",
    "cv2.namedWindow(\"Frame\")\n",
    "cv2.setMouseCallback(\"Frame\", click)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    frame = cv2.resize(frame, (0,0), fx=1, fy=1)\n",
    "    cv2.circle(frame, point, radius, color, line_width)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    ch = cv2.waitKey(1)\n",
    "    if ch & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Simple Drawing App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Global variables\n",
    "canvas = np.ones([500,500,3],'uint8')*255\n",
    "\n",
    "color = (0,255,0)\n",
    "radius = 5\n",
    "pressed = False\n",
    "\n",
    "# click callback\n",
    "def click(event, x, y, flags, param):\n",
    "    global canvas, pressed\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        pressed = True\n",
    "        cv2.circle(canvas, (x,y), radius, color,-1)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and pressed == True:\n",
    "        cv2.circle(canvas, (x,y), radius, color,-1)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        pressed = False\n",
    "\n",
    "# window initialization and callback assignment\n",
    "cv2.namedWindow(\"canvas\")\n",
    "cv2.setMouseCallback(\"canvas\", click)\n",
    "\n",
    "# Forever draw loop\n",
    "while True:\n",
    "\n",
    "    cv2.imshow(\"canvas\",canvas)\n",
    "\t# key capture every 1ms\n",
    "    ch = cv2.waitKey(1)\n",
    "    if ch & 0xFF == ord('q'):\n",
    "        break\n",
    "    elif ch & 0xFF == ord('b'):\n",
    "        color = (255,0,0)\n",
    "    elif ch & 0xFF == ord('g'):\n",
    "        color = (0,255,0)\n",
    "\t\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple thesholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "bw = cv2.imread(\"detect_blob.png\", 0)\n",
    "height, width = bw.shape[0:2]\n",
    "cv2.imshow(\"Original BW\",bw)\n",
    "\n",
    "binary = np.zeros([height, width, 1], 'uint8')\n",
    "\n",
    "thresh = 85\n",
    "\n",
    "for row in range(0,height):\n",
    "    for col in range(0, width):\n",
    "        if bw[row][col] > thresh:\n",
    "            binary[row][col] = 255\n",
    "\n",
    "cv2.imshow(\"Slow Binary\", binary)\n",
    "\n",
    "ret, thresh = cv2.threshold(bw, thresh, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"CV Threshold\", thresh)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('sudoku.png', 0)\n",
    "cv2.imshow(\"Original\", img)\n",
    "\n",
    "ret, thresh_basic = cv2.threshold(img, 70, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"Basic Binary\", thresh_basic)\n",
    "\n",
    "thresh_adapt = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 115, 1)\n",
    "cv2.imshow(\"Adaptive Threshold\", thresh_adapt)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"faces.jpeg\", 1)\n",
    "img = cv2.resize(img, (0,0), fx=0.14, fy=0.14)\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "h = hsv[:,:,0]\n",
    "s = hsv[:,:,1]\n",
    "v = hsv[:,:,2]\n",
    "\n",
    "hsv_split = np.concatenate((h,s,v), axis=1)\n",
    "cv2.imshow(\"Split HSV\", hsv_split)\n",
    "\n",
    "ret, min_sat = cv2.threshold(s, 40, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"Sat Filter\", min_sat)\n",
    "\n",
    "ret, max_hue = cv2.threshold(h, 15, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"Hue Filter\", max_hue)\n",
    "\n",
    "final = cv2.bitwise_and(min_sat, max_hue)\n",
    "cv2.imshow(\"Final\", final)\n",
    "\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contour object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"detect_blob.png\", 1)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 155, 1)\n",
    "cv2.imshow(\"Binary\", thresh)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "img2 = img.copy()\n",
    "index = -1\n",
    "thickness = 4\n",
    "color = (255,0,255)\n",
    "\n",
    "cv2.drawContours(img2, contours, index, color, thickness)\n",
    "cv2.imshow(\"Contours\", img2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area, Perimerter, center, and curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Area: 13097.0, Perimeter: 752.6274166107178\nArea: 0.0, Perimeter: 0.0\nArea: 10067.0, Perimeter: 400.8284270763397\nArea: 7785.0, Perimeter: 329.22034418582916\nArea: 4160.0, Perimeter: 258.0\nArea: 1672.0, Perimeter: 160.48528122901917\nArea: 14530.5, Perimeter: 1226.3544620275497\nArea: 5617.5, Perimeter: 450.0660150051117\nArea: 7758.0, Perimeter: 485.65685415267944\nArea: 1017.5, Perimeter: 137.49747359752655\nArea: 5026.0, Perimeter: 444.3675308227539\nArea: 8836.0, Perimeter: 449.7644990682602\nArea: 551.5, Perimeter: 93.41421353816986\nArea: 2706.5, Perimeter: 194.7523068189621\nArea: 1647.5, Perimeter: 152.12489080429077\nArea: 764.0, Perimeter: 105.74011421203613\nArea: 3497.5, Perimeter: 251.0710676908493\nArea: 8558.5, Perimeter: 346.2914116382599\nArea: 8871.0, Perimeter: 378.8284270763397\nArea: 750.0, Perimeter: 102.9116872549057\nArea: 1642.0, Perimeter: 152.36753058433533\nArea: 1.0, Perimeter: 4114.82842707634\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"detect_blob.png\", 1)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 155, 1)\n",
    "cv2.imshow(\"Binary\", thresh)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "img2 = img.copy()\n",
    "index = -1\n",
    "thickness = 4\n",
    "color = (255,0,255)\n",
    "\n",
    "objects = np.zeros([img.shape[0], img.shape[1], 3], 'uint8')\n",
    "for c in contours:\n",
    "    cv2.drawContours(objects, [c], -1, color, -1)\n",
    "\n",
    "    area = cv2.contourArea(c)\n",
    "    perimeter = cv2.arcLength(c, True)\n",
    "    \n",
    "    M = cv2.moments(c)\n",
    "    \n",
    "    try:\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        cv2.circle(objects, (cx, cy), 4, (0,0,255), -1)\n",
    "    except:\n",
    "        pass\n",
    "    print(\"Area: {}, Perimeter: {}\".format(area, perimeter))\n",
    "\n",
    "cv2.imshow(\"Contours\", objects)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canny edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"tomatoes.jpg\", 1)\n",
    "\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "res, thresh = cv2.threshold(hsv[:,:,0], 25, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"Thresh\", thresh)\n",
    "\n",
    "edges = cv2.Canny(img, 100, 70)\n",
    "cv2.imshow(\"Canny\", edges)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign object ID and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1952\n3\n4915.0 304.85281229019165\n29855.0 810.6416970491409\n17276.0 563.1370830535889\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "img = cv2.imread(\"fuzzy.png\",1)\n",
    "cv2.imshow(\"Original\", img)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "\n",
    "thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 155, 1)\n",
    "cv2.imshow(\"Binary\", thresh)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print(len(contours))\n",
    "\n",
    "filtered = []\n",
    "for c in contours:\n",
    "    if cv2.contourArea(c) < 3000:\n",
    "        continue\n",
    "    filtered.append(c)\n",
    "\n",
    "print(len(filtered))\n",
    "\n",
    "objects = np.zeros([img.shape[0], img.shape[1], 3], 'uint8')\n",
    "for c in filtered:\n",
    "    col = (random.randint(0,255), random.randint(0,255), random.randint(0,255))\n",
    "    cv2.drawContours(objects,[c], -1, col, -1)\n",
    "    area = cv2.contourArea(c)\n",
    "    p = cv2.arcLength(c,True)\n",
    "    print(area,p)\n",
    "\n",
    "cv2.imshow(\"Contours\", objects)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of template matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "template = cv2.imread('template.jpg',0)\n",
    "frame = cv2.imread(\"players.jpg\",0)\n",
    "\n",
    "cv2.imshow(\"Frame\", frame)\n",
    "cv2.imshow(\"Template\", template)\n",
    "\n",
    "result = cv2.matchTemplate(frame, template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "cv2.circle(result, max_loc, 15,255, 2)\n",
    "cv2.imshow(\"Matching\", result)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "26\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"faces.jpeg\", 1)\n",
    "img = cv2.resize(img, (0,0), fx=.2, fy=.2)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "path = \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(path)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=5, minSize=(40,40))\n",
    "print(len(faces))\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0,225, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eye Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "40\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"faces.jpeg\", 1)\n",
    "img = cv2.resize(img, (0,0), fx=.2, fy=.2)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "path = \"haarcascade_eye.xml\"\n",
    "\n",
    "eye_cascade = cv2.CascadeClassifier(path)\n",
    "\n",
    "eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.004, minNeighbors=20, minSize=(10,10))\n",
    "print(len(eyes))\n",
    "\n",
    "for (x, y, w, h) in eyes:\n",
    "    xc = (x + x+w)/2\n",
    "    yc = (y + y+h)/2\n",
    "    radius = w/2\n",
    "    cv2.circle(img, (int(xc), int(yc)), int(radius), (255,0,0), 2)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}